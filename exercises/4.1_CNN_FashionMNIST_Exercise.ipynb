{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification using Convolutional Neural Network\n",
    "\n",
    "After implemented an image classificator for the FashionMNIST dataset using a simple neural network we want to use a CNN now.  We're also going to use Keras in order to build our model.\n",
    "\n",
    "\n",
    "## Data\n",
    "\n",
    "We'll use the same data as for clustering. However, for this exercise we need training and testing samples, so that we can test how well our model performs. Test data is useful to observe that our model is not only memorizing the samples, but it should be able to classify unseen data. Therefore, we don't provide the model with labels in the test phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We are already familiar with the load_data function\n",
    "...\n",
    "\n",
    "# Note there are 60,000 training data of image size of 28x28, 60,000 train labels\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of training and test datasets\n",
    "print(x_train.shape[0], 'train set')\n",
    "print(x_test.shape[0], 'test set')\n",
    "\n",
    "# Define text labels\n",
    "fashion_mnist_labels = [\"T-shirt/top\",  # index 0\n",
    "                        \"Trouser\",      # index 1\n",
    "                        \"Pullover\",     # index 2 \n",
    "                        \"Dress\",        # index 3 \n",
    "                        \"Coat\",         # index 4\n",
    "                        \"Sandal\",       # index 5\n",
    "                        \"Shirt\",        # index 6 \n",
    "                        \"Sneaker\",      # index 7 \n",
    "                        \"Bag\",          # index 8 \n",
    "                        \"Ankle boot\"]   # index 9\n",
    "\n",
    "# Image index, it is random between 0 and 59,999\n",
    "img_index = 7\n",
    "\n",
    "# y_train contains the labels from 0 to 9\n",
    "label_index = y_train[img_index]\n",
    "\n",
    "# Print for example 2 Pullover\n",
    "print (\"y = \" + str(label_index) + \" \" +(fashion_mnist_labels[label_index]))\n",
    "\n",
    "# Show one of the images\n",
    "plt.imshow(x_train[img_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "Nearly the same thing as in the previous exercise. So you only can click through it.\n",
    "We normalize the data dimensions so that they are of approximately the same scale.\n",
    "\n",
    "Then we split into train/validation and test data sets:\n",
    "\n",
    "*   Training data - used for training \n",
    "*   Validation data - used for evaluate the models\n",
    "*   Test data - used to test the model \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing color values\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "print(\"train data - \" + str(len(x_train)))\n",
    "print(\"test data - \" + str(len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data into train / validation sets (5000 into validation set and 55,000 for train)\n",
    "(x_train, x_valid) = x_train[5000:], x_train[:5000] \n",
    "(y_train, y_valid) = y_train[5000:], y_train[:5000]\n",
    "\n",
    "# Reshape from (28, 28) to (28, 28, 1)\n",
    "w, h = 28, 28\n",
    "x_train = x_train.reshape(x_train.shape[0], w, h, 1)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], w, h, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], w, h, 1)\n",
    "\n",
    "# One-hot encode the labels to vectors of the shape 10\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_valid = tf.keras.utils.to_categorical(y_valid, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Training set shape\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "\n",
    "# Number of training, validation, and test datasets\n",
    "print(x_train.shape[0], 'train set')\n",
    "print(x_valid.shape[0], 'validation set')\n",
    "print(x_test.shape[0], 'test set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and train the model\n",
    "In Keras there are two APIs for model architecure:\n",
    "- `Sequential` model API\n",
    "- `Functional` API\n",
    "\n",
    "Here we use Sequential model API, because our model has no recursions.\n",
    "Additionally in defining the model we will use some of these Keras APIs:\n",
    "- `Conv2D()` - convolutional layer\n",
    "- `Pooling()` - pooling layer\n",
    "- `Dropout()` - apply drop out\n",
    "\n",
    "Define you model with the elements needed for a CNN model.\n",
    "\n",
    "***Hint:***\n",
    "\n",
    "The network structure looks like that:\n",
    "- `Conv2D` - use the right input_shape and relu activation!\n",
    "- `MaxPooling2D` - pool size 2\n",
    "- `Dropout` - choose the right dropout rate!\n",
    "\n",
    "\n",
    "- `Conv2D` - relu activation\n",
    "- `MaxPooling2D` - pool size 2\n",
    "- `Dropout` choose the right dropout rate!\n",
    "\n",
    "\n",
    "- `Flatten`\n",
    "- `Dense` - relu activation\n",
    "- `Dropout` choose the right dropout rate!\n",
    "- `Dense` - with number of output classes and softmax activation\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Must define the input shape in the first layer of the neural network\n",
    "\n",
    "...\n",
    "\n",
    "# Take a look at the model summary\n",
    "model.summary()\n",
    "\n",
    "# Configuring the learning process with compile()-API\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train the model with `fit()` API. You might remember this method from the previous exercise.\n",
    "\n",
    "We use the `ModelCheckpoint` API to save the model after every epoch. Set \"save_best_only = True\" to save only when the validation accuracy improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "checkpointer = ModelCheckpoint(filepath='modelCNN.hdf5', verbose = 1, save_best_only=True)\n",
    "\n",
    "#implement the fit method \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we are reloading the trained model. Therefore we use the method `load_weights()`. \n",
    "\n",
    "***Hint:***\n",
    "You will need the saved checkpoint model, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weights with the best validation accuracy\n",
    "...\n",
    "\n",
    "# Evaluate the model on test set\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "# Print test accuracy\n",
    "print('\\n', 'Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visialize the predictions\n",
    "Now let's visualize the prediction using the model you just trained. We print 15 images from the test data set, and their corresponding prediction class. If the prediction matches the true label, the title will be green; otherwise it's displayed in red. \n",
    "\n",
    "***Hint:***\n",
    "First use the `predict` method you already know from the ANN exercise. But this time without \"classes\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the predict method the use our model for test data predictions\n",
    "y_hat = ...\n",
    "\n",
    "# Show a random sample of 10 test images, their predicted labels and ground truth\n",
    "figure = plt.figure(figsize=(20, 8))\n",
    "for i, index in enumerate(np.random.choice(x_test.shape[0], size=15, replace=False)):\n",
    "    ax = figure.add_subplot(3, 5, i + 1, xticks=[], yticks=[])\n",
    "    # Display each \n",
    "    ax.imshow(np.squeeze(x_test[index]))\n",
    "    predict_index = np.argmax(y_hat[index])\n",
    "    true_index = np.argmax(y_test[index])\n",
    "    # Set the title for each \n",
    "    ax.set_title(\"{} ({})\".format(fashion_mnist_labels[predict_index], \n",
    "                                  fashion_mnist_labels[true_index]),\n",
    "                                  color=(\"green\" if predict_index == true_index else \"red\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything worked, nearly all images were predicted right!\n",
    "Your test accuracy should be around 90%!\n",
    "\n",
    "Now, you have successfully trained a CNN to classify fashion-MNIST. Congratulations!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
