{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Processing\n",
    "\n",
    "In this exercise we will learn how to perform text classification. For instance we will perform sentiment analisys on movie reviews. You have a folder *./data/polarity_data/* with two files one with positive and one negative with negative reviews.\n",
    "\n",
    "First we will import some packages that we need for our task and here we go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's do we have to do first?\n",
    "Get in contact with the data. How does it look like? Do we need to delete something? Take a look at the data, think about the polarity, do you agree with the sentiment? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's next?\n",
    "Prepare the data. \n",
    "\n",
    "**How?** \n",
    "\n",
    "Could you see how many reviews do we have in each file? \n",
    "The idea is that you read those files merge them into one and create labels for them.\n",
    "\n",
    "\n",
    "\n",
    "***Hint:***\n",
    "If you open a file using readlines, it would return a list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create the labels. You might remember that we already imported pandas and numpy. \n",
    "\n",
    "***Hint 1:***\n",
    "Remember to use numerical values as labels, for example positive 0 and negative 1. Or viceversa.\n",
    "\n",
    "**Hint 2:**\n",
    "The numpy function full creates a vector with a desired shape and fullfils it with a desired value. Create your vectors and concatenate them into one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally models do not process text but a numerical version of it. Therefore we need to vectorize our data. There are several ways of doing it. One could be calculating Tf-Idf for each document.\n",
    "\n",
    "In order to vectorize our data, we can use the Tf-Idf function from SkLearn and test our model on the preprocessed data. The resulting vector from this operation is the input to train and test our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will need to create store your data in X_train, y_train, X_test, y_test\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having our datasets, we can vectorize them using a Tf-Idf function from SkLearn and test our model on the preprocessed data. This vector is the input to train and test our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment lines to run the model.\n",
    "# vectorizer = TfidfVectorizer(ngram_range=(1, 3), min_df=5)\n",
    "# trainMatrixTfidf = vectorizer.fit_transform(X_train)\n",
    "# trainInput = trainMatrixTfidf\n",
    "# clf = svm.LinearSVC()\n",
    "# clf.fit(trainingsInput, y_train)\n",
    "# testMatrixTfidf = vectorizer.transform(X_test)\n",
    "# test = clf.predict(testMatrixTfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our last step is to calculate accuracy, which is relevant in this case, since we already know that this corpus is balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you still have extra time try following the same steps this our tweets data. Data: *./data/twitter_data/testdata.csv*\n",
    "\n",
    "**Note:** This data contain 3 classes, positive, negative and neutral, you can extract positive and negative tweets and work with them. \n",
    "\n",
    "Here is the data format:\n",
    "* The polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)\n",
    "* The id of the tweet (2087)\n",
    "* The date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
    "* The query (lyx). If there is no query, then this value is NO_QUERY.\n",
    "* The user that tweeted (robotickilldozr)\n",
    "* The text of the tweet (Lyx is cool)\n",
    "\n",
    "Also make sure that you read correctly the files, those are csv files that might be easily read using the function _read_csv_ from pandas. Maybe you can compare both read-file-functions and note the advantages of both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to extract only text and labels. You might also consider deleting punctuation and weird stuff that might misslead your model.\n",
    "\n",
    "**Hint:** Check the _iterrows_ function in pandas to iterate over each row in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now is your time to feed this data again into a model and check it's performance :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
