{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summer School Workshop - Image Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may have heard in the lecture, most machine learning algorithms need the data in a fixed and uniform format. For image data, this means a fixed size, resolution, color depth and so on.\n",
    "Luckily, most deep learning frameworks already include high-level interfaces for image transformation, so that the data can be transformed into a useful format quite easily. The result of the preprocessing should be simply a byte array for each image that we can feed into a neural network.\n",
    "\n",
    "In this exercise we learn how to preprocess image data. Our goal will be an optimal training result.\n",
    "\n",
    "Steps:\n",
    "- Explore the raw data\n",
    "- Structure the dataset\n",
    "- Standardize the size\n",
    "- Split into training and testing data\n",
    "- Augment the data to have a greater variety "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some standard imports \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already obtained some raw data for you. \n",
    "In the folder ['data/image_cats_dogs'](/tree/data/image_cats_dogs) are 100 cat and 100 dog images. The images come from the dataset of the Kaggle challenge ['Dogs vs. Cats'](https://www.kaggle.com/c/dogs-vs-cats)\n",
    "\n",
    "We want to prepared these images now in order to train a dog vs. cat classifier\n",
    "\n",
    "- Take a look at the folder and become familiar with the images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our current path\n",
    "print(\"current path: {}\".format(os.getcwd()))\n",
    "\n",
    "# let's save the home path: this value is for the container environment. \n",
    "# You can update the path according to the outputof the command above\n",
    "home = \"/home/jovyan/\"\n",
    "\n",
    "folders = {home + \"data/image_cats_dogs/\"}\n",
    "for folder in folders:\n",
    "    for i, file in zip(range(4),os.listdir(folder)):\n",
    "        display(Image(filename=(folder + file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Structure your dataset\n",
    "\n",
    "We should first copy the files to a new location in order to avoid having to redownload them in the case of erros in the preprocessing. \n",
    "\n",
    "Because its also ofthen easier to have the classes in seperate locations, we'll seperate cats images from dog images in this step, too. Most toolkits are then able to map the name of a directory to a specfic class. \n",
    "\n",
    "The information if an image shows a cat or a dog, the labels, are contained in the file ['data/catdoglabels.csv'](/edit/data/catdoglabels.csv).\n",
    "\n",
    "- Therefore structure the data using the csv file into two subfolders based on the schema below:\n",
    "\n",
    "```\n",
    "- Images folder\n",
    "    -cat:\n",
    "        -u27.jpg\n",
    "        -099.jpg\n",
    "        -...\n",
    "    -dog:\n",
    "        -866.jpg\n",
    "        -783.jpg\n",
    "        -...\n",
    "```        \n",
    "This can be done by completing the following Python code:\n",
    "\n",
    "**Hint:** read the csv into a pandas dataframe, which is basically a table structure that you can access like a hash map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv file with pandas\n",
    "pd.read_csv?\n",
    "csvlabels = ...\n",
    "\n",
    "# define a mapping from the integer label (0/1) to a human readable class label (cats/dogs)\n",
    "labels = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is already complete because it is mostly boring file operation...\n",
    "\n",
    "# define source folder and our working folder in which we store the copy of the data\n",
    "source_folder = home + \"data/image_cats_dogs/\"\n",
    "target_folder = home + \"temp/image_cats_dogs/\"\n",
    "\n",
    "# create folder structure if necessary\n",
    "os.makedirs(target_folder, exist_ok=True)\n",
    "\n",
    "# create the folders for each class\n",
    "for i in range(2):\n",
    "    label = labels[i]\n",
    "    path =  target_folder + label + \"/\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# loop through the images\n",
    "copy_count = 0;\n",
    "for file in os.listdir(source_folder):\n",
    "    # search for the label\n",
    "    label = csvlabels[csvlabels.id == file.replace(\".jpg\",\"\")].label.values[0]\n",
    "    # copy it\n",
    "    shutil.copy((source_folder+file), (target_folder+labels[label]+\"/\"))\n",
    "    copy_count += 1\n",
    "print(\"{} files copied\".format(copy_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Standardise sizes\n",
    "\n",
    "Most machine learning methods need a fix input size. This is why we normalize the image size to an uniform, square format. \n",
    "\n",
    "We work with an (arbitrary) image size of 250 x 250 pixels. Far more than the Fashion MNIST dataset, but still small. \n",
    "\n",
    "Step1: Make the image square by cutting surplus image parts from either top/bottom or left/right (cropping).\n",
    "\n",
    "Step2: Resize the square image to a fixed resolution of 250 x 250 pixels (thumbnailing). \n",
    "\n",
    "Therefore complete the following code with a crop method!\n",
    "\n",
    "***Hints:***\n",
    "- `PIL.Image` has a `crop` as well as a `thumbnail` method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as PILImage # name conflict with IPython.display.Image\n",
    "DESIRED_SIZE = 250, 250\n",
    "\n",
    "count = 0\n",
    "# goes through all folders\n",
    "for root, dirs, files in os.walk(target_folder):\n",
    "    # for each folder: goes through each file\n",
    "    for pic in files:\n",
    "        #loads image\n",
    "        img_path = os.path.join(root, pic)\n",
    "        img = PILImage.open(img_path)\n",
    "        width, height = img.size\n",
    "       \n",
    "        if width > height:\n",
    "            left = int((width-height)/2)\n",
    "             #insert the crop method here!\n",
    "             \n",
    "        else:\n",
    "            upper = int((height-width)/2)\n",
    "            #insert the crop method here!\n",
    "\n",
    "        # this code resizes the cropped image and overwrites the file with the transformed image.\n",
    "        img.thumbnail(DESIRED_SIZE, PILImage.ANTIALIAS)\n",
    "        img.save(os.path.join(root, pic))\n",
    "        count += 1\n",
    "print('{} images done'.format(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now open a few images with the display method to check if it worked! The images should all be squared and constant size with a nicely cropped animal.\n",
    "(code is already provided, just run it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfImageNames = [target_folder + labels[1] + '/1v4.jpg',\n",
    "                    target_folder + labels[1] + '/4vv.jpg',\n",
    "                    target_folder + labels[0] + '/x12.jpg',\n",
    "                    target_folder + labels[0] + '/x13.jpg']\n",
    "\n",
    "for imageName in listOfImageNames:\n",
    "    display(Image(filename=imageName))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create a test set\n",
    "\n",
    "To recognize if the learning method does not simply memorize the examples, we won't show him a part of the examples during the training. If the model can predict well for those data examples, we know that it have learned something useful.\n",
    "   \n",
    "Take 80% of all data for training data and 20% for test data, and move them into separate directories:\n",
    "\n",
    "```\n",
    "- Images folder\n",
    "    - train\n",
    "        -cat:\n",
    "            -u27.jpg\n",
    "            -099.jpg\n",
    "            -...\n",
    "        -dog:\n",
    "            -866.jpg\n",
    "            -783.jpg\n",
    "            -...\n",
    "    - test\n",
    "        -cat:\n",
    "            -f11.jpg\n",
    "            -d84.jpg\n",
    "            -...\n",
    "        -dog:\n",
    "            -0h7.jpg\n",
    "            -110.jpg\n",
    "            -...\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# In order to guarantee that both classes are also evenly distributed in the test set, \n",
    "# we process them separatly \n",
    "for i in range(2):\n",
    "    filenames = os.listdir(target_folder + labels[i])\n",
    "    # shuffle to generate a random split \n",
    "    random.shuffle(filenames) \n",
    "    # insert your code to split the data into two parts!\n",
    "    split_index = ...\n",
    "    # insert your code to make dirs and move the files\n",
    "    shutil.move?\n",
    "\n",
    "\n",
    "# delete old dirs if your are certain that everything works :)\n",
    "#for i in range(2):\n",
    "#    os.removedirs(target_folder + labels[i])\n",
    "    \n",
    "# what's the result?\n",
    "for folder in os.walk(target_folder):\n",
    "    print(\"folder: {}, file count: {}\".format(folder[0], len(folder[2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Expand your train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the fact that our previous dataset is very small, we want to expand it. One way of achieving this is called 'Data Augmentation'. Within different transformation steps like rotation or perspectives we create further versions of an image. It helps the model to generalize better and it prevents overfitting.\n",
    "- First search for information about Data Augmentation in our NovaTec-Blog (https://blog.novatec-gmbh.de/keras-data-augmentation-for-cnn/)\n",
    "- After that apply Data Augmentation to one example image of your choice. Take note how different parameters affect the images!\n",
    "- Complete the code by an ImageDataGenerator(https://keras.io/preprocessing/image/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from IPython.display import Image, display\n",
    "\n",
    "#ImageDataGenerator datagen:\n",
    "datagen = # your code here!\n",
    "\n",
    "# \n",
    "img = load_img('../temp/image_cats_dogs/train/dog/0h7.jpg')  # you may have to change this file name! (random split 4TW!)\n",
    "x = img_to_array(img)  # Numpy array with shape (250, 250, 3)\n",
    "x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 250, 250, 3)\n",
    "    \n",
    "    \n",
    "# generating batches of randomly transformed images\n",
    "# save to the 'augmentation' directory\n",
    "if not os.path.exists('../temp/image_cats_dogs/augmentation'):\n",
    "    os.makedirs('../temp/image_cats_dogs/augmentation')\n",
    "        \n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1, save_to_dir='../temp/image_cats_dogs/augmentation', save_prefix='dog', save_format='jpeg'):\n",
    "    i += 1\n",
    "    # 10 images\n",
    "    if i > 9:\n",
    "        break \n",
    "    \n",
    "listOfAugmentedImages = []\n",
    "for root, dirs, files in os.walk('../temp/image_cats_dogs/augmentation/'):\n",
    "    for pic in files:\n",
    "        listOfAugmentedImages.append(os.path.join(root,pic))\n",
    "        \n",
    "for imageName in listOfAugmentedImages:\n",
    "        display(Image(filename=imageName))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Convert to byte array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data input into a neural net (convolutional neural net) must be available in byte format. For CNNs this would be a 4-D input tensor with the values `[batch_size, width, height, channels]`.\n",
    "- Convert one image of your choice and output a byte array with shape `[1,250, 250, 3]`.\n",
    "\n",
    "***Hint***: Use the Keras method 'img_to_array'!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "image = Image.open(target_folder +'train/'+ labels[1] + '/0jj.jpg', 'r')\n",
    "\n",
    "#insert the method here:\n",
    "image = ...\n",
    "print ('Shape:', image.shape)\n",
    "imshow(image)\n",
    "\n",
    "image = image / 255\n",
    "image = np.expand_dims(image, axis=0)\n",
    "print ('Shape:', image.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
