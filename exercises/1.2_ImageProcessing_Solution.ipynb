{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summer School Workshop - Image Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most Deep Learning Frameworks already include high-level interfaces for image transformation, so that the data can be processed by the neural net. The images are converted to the same level of resolution and size. \n",
    "Furthermore a conversion to byte arrays decreases the processing time.\n",
    "\n",
    "In this workshop we work on the subject to preprocess image data. Our goal will be an optimal training result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Explore you data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already obtained your data! \n",
    "In the folder 'data/image_cats_dogs' are 100 cat and 100 dog images. The images come from the Kaggle dataset of the challenge 'Dogs vs. Cats':  https://www.kaggle.com/c/dogs-vs-cats\\\n",
    "\n",
    "These images should be prepared now. As a result a dog vs. cat classifier can be trained on the basis of the prepared data. \n",
    "- Take a look at the folder and become familiar with the images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our current path\n",
    "print(\"current path: {}\".format(os.getcwd()))\n",
    "\n",
    "# let's save the home path\n",
    "home = \"/home/jovyan/\"\n",
    "\n",
    "folders = {home + \"data/image_cats_dogs/\"}\n",
    "for folder in folders:\n",
    "    for i, file in zip(range(4),os.listdir(folder)):\n",
    "        display(Image(filename=(folder + file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparing Data\n",
    "\n",
    "For further steps it's easier to separate the image classes into different directories. The most toolkits are able to map the name of a directory to a specfic class. \n",
    "\n",
    "The file *~/data/catdoglabels.csv* contains for each image name the correct class.\n",
    "\n",
    "- Therefore structure the data using the csv file into two subfolders based on the schema below:\n",
    "    - Images\n",
    "        \n",
    "        -1 (Label Dog):\n",
    "            -866.jpg\n",
    "            -783.jpg\n",
    "            -...\n",
    "        -0 (Label Cat):\n",
    "            -u27.jpg\n",
    "            -099.jpg\n",
    "            -...\n",
    "This could be done by completing the Python code with some lines..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the csv file with the pandas library\n",
    "csvlabels = pd.read_csv(home + \"data/catdoglabels.csv\")\n",
    "print (\"data size:\", csvlabels.shape)\n",
    "labels = { 0 : \"cat\", 1 : \"dog\"}\n",
    "csvlabels.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the folders for each class\n",
    "source_folder = home + \"data/image_cats_dogs/\"\n",
    "target_folder = home + \"temp/image_cats_dogs/\"\n",
    "\n",
    "if not os.path.exists(target_folder):\n",
    "    os.makedirs(target_folder)\n",
    "for i in range(2):\n",
    "    label = labels[i]\n",
    "    path =  target_folder + label + \"/\"\n",
    "    if not os.path.exists(path):\n",
    "        print ('Generated subfolder:', label)\n",
    "        os.makedirs(path)\n",
    "\n",
    "# loop through the images\n",
    "copy_count = 0;\n",
    "for file in os.listdir(source_folder):\n",
    "    # search for the label\n",
    "    label = csvlabels[csvlabels.id == file.replace(\".jpg\",\"\")].label.values[0]\n",
    "    # copy it\n",
    "    shutil.copy((source_folder+file), (target_folder+labels[label]+\"/\"))\n",
    "    copy_count += 1\n",
    "print(\"{} files copied\".format(copy_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Standardise size\n",
    "\n",
    "Most machine learning methods need a fix input size. This is why we normalize the image size to an uniform, square format. \n",
    "\n",
    "Additionally we work with an image size of 250 x 250 pixels. Far more than the Fashion MNIST dataset, but still small. \n",
    "\n",
    "Surplus image parts will be cropped (Cropping).\n",
    "\n",
    "***Hints:***\n",
    "- `PIL.Image` has a `crop` as well as a `thumbnail` method\n",
    "\n",
    "  \n",
    "Crop all images to a resolution 250 x 250 pixels and use the Python Imaging Library (PIL). Therefore complete the following code with a crop method!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as PILImage # name conflict with IPython.display.Image\n",
    "DESIRED_SIZE = 250, 250\n",
    "\n",
    "count = 0\n",
    "for root, dirs, files in os.walk(target_folder):\n",
    "    for pic in files:\n",
    "        img_path = os.path.join(root, pic)\n",
    "        img = PILImage.open(img_path)\n",
    "        width, height = img.size\n",
    "\n",
    "        #insert the crop method here!\n",
    "        if width > height:\n",
    "            left = int((width-height)/2)\n",
    "            img = img.crop((left, 0, left+height, height))\n",
    "        else:\n",
    "            upper = int((height-width)/2)\n",
    "            img = img.crop((0, upper, width, upper+width))\n",
    "\n",
    "        img.thumbnail(DESIRED_SIZE, PILImage.ANTIALIAS)\n",
    "        img.save(os.path.join(root, pic))\n",
    "        count += 1\n",
    "print('{} images done'.format(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now open a few images with the display method to check if it works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfImageNames = [target_folder + labels[1] + '/1v4.jpg',\n",
    "                    target_folder + labels[1] + '/4vv.jpg',\n",
    "                    target_folder + labels[0] + '/x12.jpg',\n",
    "                    target_folder + labels[0] + '/x13.jpg']\n",
    "\n",
    "for imageName in listOfImageNames:\n",
    "    display(Image(filename=imageName))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create a test dataset\n",
    "\n",
    "To recognize if the learning method does not simply memorize the examples, we won't show him a part of the examples during the training. If the model can predict well for those data examples, we know that it have learned something useful.\n",
    "   \n",
    "Take 80% of all data for training data and 20% for test data, and move them into separate directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# In order that both classes are also evenly distributed in the test set, \n",
    "# we process them separate \n",
    "for i in range(2):\n",
    "    filenames = os.listdir(target_folder + labels[i])\n",
    "    # shuffle to generate a random split \n",
    "    random.shuffle(filenames) \n",
    "    # split\n",
    "    split_index = int(0.8 * len(filenames))\n",
    "    split_files = {}\n",
    "    split_files['train'] = filenames[:split_index]\n",
    "    split_files['test'] = filenames[split_index:]\n",
    "    for set in [\"train\",\"test\"]:\n",
    "        # make dir and move\n",
    "        os.makedirs(target_folder + set + '/' + labels[i], exist_ok=True)\n",
    "        for file in split_files[set]:\n",
    "            shutil.move(\n",
    "                target_folder + labels[i] + \"/\" + file,\n",
    "                target_folder + set + '/' + labels[i] + \"/\" + file)\n",
    "\n",
    "# delete old dirs\n",
    "for i in range(2):\n",
    "    os.removedirs(target_folder + labels[i])\n",
    "    \n",
    "# what's the result?\n",
    "for folder in os.walk(target_folder):\n",
    "    print(\"folder: {}, file count: {}\".format(folder[0], len(folder[2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Expand your train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the fact that our previous dataset is too small for a successful training, we have to expand it. One way of achieving this is called 'Data Augmentation'. Within different transformation steps like rotation or perspectives we create further versions of an image. It helps the model to generalize better and it prevents overfitting.\n",
    "- First search for information about Data Augmentation in our NovaTec-Blog (https://blog.novatec-gmbh.de/keras-data-augmentation-for-cnn/)\n",
    "- After that apply Data Augmentation to one example image of your choice. Take note how different parameters affect the images!\n",
    "- Complete the code by an ImageDataGenerator(https://keras.io/preprocessing/image/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from IPython.display import Image, display\n",
    "\n",
    "#ImageDataGenerator datagen:\n",
    "datagen = ImageDataGenerator(\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,\n",
    "            shear_range=0.1,\n",
    "            zoom_range=0.1,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest')\n",
    "    \n",
    "img = load_img('../temp/image_cats_dogs/train/dog/0h7.jpg')  \n",
    "x = img_to_array(img)  # Numpy array with shape (250, 250, 3)\n",
    "x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 250, 250, 3)\n",
    "    \n",
    "    \n",
    "# generating batches of randomly transformed images\n",
    "# save to the 'augmentation' directory\n",
    "if not os.path.exists('../temp/image_cats_dogs/augmentation'):\n",
    "    os.makedirs('../temp/image_cats_dogs/augmentation')\n",
    "        \n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1, save_to_dir='../temp/image_cats_dogs/augmentation', save_prefix='dog', save_format='jpeg'):\n",
    "    i += 1\n",
    "    # 10 images\n",
    "    if i > 9:\n",
    "        break \n",
    "    \n",
    "listOfAugmentedImages = []\n",
    "for root, dirs, files in os.walk('../temp/image_cats_dogs/augmentation/'):\n",
    "    for pic in files:\n",
    "        listOfAugmentedImages.append(os.path.join(root,pic))\n",
    "        \n",
    "for imageName in listOfAugmentedImages:\n",
    "        display(Image(filename=imageName))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Convert to Byte-Array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data input into a neural net (convolutional neural net) must be available in byte format. For CNNs this would be a 4-D input tensor with the values [batch_size, width, height, channels].\n",
    "- Convert one image of your choice and output a byte array with shape [1,250, 250, 3].\n",
    "\n",
    "Hint: Use the Keras method 'img_to_array'!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "image = Image.open(target_folder +'train/'+ labels[1] + '/0jj.jpg', 'r')\n",
    "\n",
    "#insert the method here:\n",
    "image = img_to_array(image)\n",
    "print ('Shape:', image.shape)\n",
    "imshow(image)\n",
    "\n",
    "image = image / 255\n",
    "image = np.expand_dims(image, axis=0)\n",
    "print ('Shape:', image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
